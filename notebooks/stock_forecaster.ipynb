{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5a1550e-6b74-48a1-8fc2-04ca2f6f7238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "curr_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(curr_dir)\n",
    "sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b212ed15-0b09-4c73-8017-e466dbadafca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35903fe9-a222-4ff1-8aad-3a103b2b5038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 22:56:05.589179: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-03 22:56:08.883155: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-03 22:56:08.888032: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-03 22:56:16.922367: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from scripts.stock_forecasting import StockForecasting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1abda50-1eb2-4bd3-af18-2ccc609a455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the StockForecasting clas and preprocess to run stock forcasting processes\n",
    "preprocessed_data = pd.read_csv(\"../data/preprocessed_data.csv\", index_col=0)\n",
    "ticker = \"TSLA\"\n",
    "stock_forecasting = StockForecasting(preprocessed_data, ticker)\n",
    "stock_forecasting.retrieve_data_by_ticker(ticker, inplace=True)\n",
    "stock_forecasting.normalize_data()\n",
    "stock_forecasting.split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7cd75a4-cd25-4e9e-b148-624d96e84833",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/am/Documents/Software Development/10_Academy Training/week-11/portfolio-management-optimization/v-portfolio/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/am/Documents/Software Development/10_Academy Training/week-11/portfolio-management-optimization/v-portfolio/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/am/Documents/Software Development/10_Academy Training/week-11/portfolio-management-optimization/v-portfolio/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/am/Documents/Software Development/10_Academy Training/week-11/portfolio-management-optimization/v-portfolio/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/am/Documents/Software Development/10_Academy Training/week-11/portfolio-management-optimization/v-portfolio/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            7     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.43062D+00    |proj g|=  3.25555D-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    5    f=  3.40350D+00    |proj g|=  3.68721D-03\n",
      "\n",
      "At iterate   10    f=  3.40349D+00    |proj g|=  1.24974D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    7     10     12      1     0     0   1.250D-05   3.403D+00\n",
      "  F =   3.4034876681079189     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Epoch 1/30\n",
      "62/62 [==============================] - 7s 41ms/step - loss: 0.0066\n",
      "Epoch 2/30\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 7.6214e-04\n",
      "Epoch 3/30\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 7.0558e-04\n",
      "Epoch 4/30\n",
      "62/62 [==============================] - 2s 38ms/step - loss: 6.4209e-04\n",
      "Epoch 5/30\n",
      "62/62 [==============================] - 2s 37ms/step - loss: 5.5712e-04\n",
      "Epoch 6/30\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 4.8433e-04\n",
      "Epoch 7/30\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 4.5992e-04\n",
      "Epoch 8/30\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 4.2427e-04\n",
      "Epoch 9/30\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 4.1259e-04\n",
      "Epoch 10/30\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.6933e-04\n",
      "Epoch 11/30\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 4.3140e-04\n",
      "Epoch 12/30\n",
      "62/62 [==============================] - 2s 38ms/step - loss: 3.9006e-04\n",
      "Epoch 13/30\n",
      "62/62 [==============================] - 2s 37ms/step - loss: 3.1758e-04\n",
      "Epoch 14/30\n",
      "62/62 [==============================] - 2s 35ms/step - loss: 3.3004e-04\n",
      "Epoch 15/30\n",
      "62/62 [==============================] - 2s 37ms/step - loss: 3.7117e-04\n",
      "Epoch 16/30\n",
      "62/62 [==============================] - 2s 36ms/step - loss: 3.4948e-04\n",
      "Epoch 17/30\n",
      "62/62 [==============================] - 2s 35ms/step - loss: 3.1778e-04\n",
      "Epoch 18/30\n",
      "62/62 [==============================] - 2s 36ms/step - loss: 2.6958e-04\n",
      "Epoch 19/30\n",
      "62/62 [==============================] - 2s 35ms/step - loss: 3.0430e-04\n",
      "Epoch 20/30\n",
      "62/62 [==============================] - 2s 35ms/step - loss: 2.4484e-04\n",
      "Epoch 21/30\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 2.4497e-04\n",
      "Epoch 22/30\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 2.6679e-04\n",
      "Epoch 23/30\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 2.5352e-04\n",
      "Epoch 24/30\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 2.4708e-04\n",
      "Epoch 25/30\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 2.6680e-04\n",
      "Epoch 26/30\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.6370e-04\n",
      "Epoch 27/30\n",
      "62/62 [==============================] - 2s 38ms/step - loss: 2.3212e-04\n",
      "Epoch 28/30\n",
      "62/62 [==============================] - 2s 37ms/step - loss: 2.1555e-04\n",
      "Epoch 29/30\n",
      "62/62 [==============================] - 3s 40ms/step - loss: 1.9995e-04\n",
      "Epoch 30/30\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 2.1467e-04\n"
     ]
    }
   ],
   "source": [
    "# Train models\n",
    "stock_forecasting.arima_model()\n",
    "\n",
    "# Optimize ARIMA\n",
    "stock_forecasting.optimize_arima()\n",
    "stock_forecasting.sarima_model()\n",
    "stock_forecasting.train_lstm(look_back=60, epochs=30, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e92d7211-28f9-495c-abc2-de967574108a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Optimizing ARIMA ...\n",
      "Performing stepwise search to minimize aic\n",
      " ARIMA(2,1,2)(1,0,1)[5] intercept   : AIC=16556.773, Time=16.08 sec\n",
      " ARIMA(0,1,0)(0,0,0)[5] intercept   : AIC=16568.519, Time=0.12 sec\n",
      " ARIMA(1,1,0)(1,0,0)[5] intercept   : AIC=16570.008, Time=2.04 sec\n",
      " ARIMA(0,1,1)(0,0,1)[5] intercept   : AIC=16569.793, Time=2.79 sec\n",
      " ARIMA(0,1,0)(0,0,0)[5]             : AIC=16567.971, Time=0.12 sec\n",
      " ARIMA(2,1,2)(0,0,1)[5] intercept   : AIC=16572.053, Time=17.72 sec\n",
      " ARIMA(2,1,2)(1,0,0)[5] intercept   : AIC=16572.617, Time=12.96 sec\n",
      " ARIMA(2,1,2)(2,0,1)[5] intercept   : AIC=16559.089, Time=27.30 sec\n",
      " ARIMA(2,1,2)(1,0,2)[5] intercept   : AIC=16559.274, Time=29.48 sec\n",
      " ARIMA(2,1,2)(0,0,0)[5] intercept   : AIC=16573.374, Time=6.80 sec\n",
      " ARIMA(2,1,2)(0,0,2)[5] intercept   : AIC=16560.704, Time=17.76 sec\n",
      " ARIMA(2,1,2)(2,0,0)[5] intercept   : AIC=16563.039, Time=20.64 sec\n",
      " ARIMA(2,1,2)(2,0,2)[5] intercept   : AIC=16556.177, Time=29.87 sec\n",
      " ARIMA(1,1,2)(2,0,2)[5] intercept   : AIC=16555.033, Time=24.16 sec\n",
      " ARIMA(1,1,2)(1,0,2)[5] intercept   : AIC=16562.223, Time=10.60 sec\n",
      " ARIMA(1,1,2)(2,0,1)[5] intercept   : AIC=16562.017, Time=10.69 sec\n",
      " ARIMA(1,1,2)(1,0,1)[5] intercept   : AIC=16561.095, Time=10.74 sec\n",
      " ARIMA(0,1,2)(2,0,2)[5] intercept   : AIC=16552.793, Time=24.80 sec\n",
      " ARIMA(0,1,2)(1,0,2)[5] intercept   : AIC=16559.982, Time=16.11 sec\n",
      " ARIMA(0,1,2)(2,0,1)[5] intercept   : AIC=16559.767, Time=10.42 sec\n",
      " ARIMA(0,1,2)(1,0,1)[5] intercept   : AIC=16559.372, Time=8.91 sec\n",
      " ARIMA(0,1,1)(2,0,2)[5] intercept   : AIC=16551.439, Time=16.02 sec\n",
      " ARIMA(0,1,1)(1,0,2)[5] intercept   : AIC=16558.377, Time=6.35 sec\n",
      " ARIMA(0,1,1)(2,0,1)[5] intercept   : AIC=16558.172, Time=6.73 sec\n",
      " ARIMA(0,1,1)(1,0,1)[5] intercept   : AIC=16557.711, Time=6.83 sec\n",
      " ARIMA(0,1,0)(2,0,2)[5] intercept   : AIC=16550.427, Time=13.40 sec\n",
      " ARIMA(0,1,0)(1,0,2)[5] intercept   : AIC=16556.809, Time=5.11 sec\n",
      " ARIMA(0,1,0)(2,0,1)[5] intercept   : AIC=16556.618, Time=3.38 sec\n",
      " ARIMA(0,1,0)(1,0,1)[5] intercept   : AIC=16556.192, Time=5.20 sec\n",
      " ARIMA(1,1,0)(2,0,2)[5] intercept   : AIC=16551.407, Time=16.23 sec\n",
      " ARIMA(1,1,1)(2,0,2)[5] intercept   : AIC=16552.656, Time=24.51 sec\n",
      " ARIMA(0,1,0)(2,0,2)[5]             : AIC=16550.061, Time=8.18 sec\n",
      " ARIMA(0,1,0)(1,0,2)[5]             : AIC=16556.834, Time=1.85 sec\n",
      " ARIMA(0,1,0)(2,0,1)[5]             : AIC=16556.618, Time=1.49 sec\n",
      " ARIMA(0,1,0)(1,0,1)[5]             : AIC=16557.064, Time=1.53 sec\n",
      " ARIMA(1,1,0)(2,0,2)[5]             : AIC=16551.106, Time=6.33 sec\n",
      " ARIMA(0,1,1)(2,0,2)[5]             : AIC=16551.137, Time=8.19 sec\n",
      " ARIMA(1,1,1)(2,0,2)[5]             : AIC=16552.337, Time=12.04 sec\n",
      "\n",
      "Best model:  ARIMA(0,1,0)(2,0,2)[5]          \n",
      "Total fit time: 444.339 seconds\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9699601b-9282-43be-8c52-c8eb9144ae83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully as /home/am/Documents/Software Development/10_Academy Training/week-11/portfolio-management-optimization/models/arima_model.pkl\n",
      "Model saved successfully as /home/am/Documents/Software Development/10_Academy Training/week-11/portfolio-management-optimization/models/sarima_model.pkl\n",
      "Model saved successfully as /home/am/Documents/Software Development/10_Academy Training/week-11/portfolio-management-optimization/models/optimized_arima_model.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/am/Documents/Software Development/10_Academy Training/week-11/portfolio-management-optimization/v-portfolio/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully as /home/am/Documents/Software Development/10_Academy Training/week-11/portfolio-management-optimization/models/lstm_model.h5\n"
     ]
    }
   ],
   "source": [
    "# Save all models\n",
    "stock_forecasting.save_all_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6d205f9-8cf0-41ce-9d98-2156997fdb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating ARIMA Model:\n",
      "ARIMA Model - MAE: 6.279581031963751, RMSE: 8.959139192524532, MAPE: 2.640428044692785\n",
      "\n",
      "Evaluating Optimized ARIMA Model:\n",
      "****************************************************************************************************\n",
      " Forecasting using Optimizing ARIMA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/am/Documents/Software Development/10_Academy Training/week-11/portfolio-management-optimization/v-portfolio/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/home/am/Documents/Software Development/10_Academy Training/week-11/portfolio-management-optimization/v-portfolio/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized ARIMA Model - MAE: 233.65287952310234, RMSE: 242.5892848450989, MAPE: 100.0\n",
      "\n",
      "Evaluating SARIMAX Model:\n",
      "SARIMAX Model - MAE: 233.65287952310234, RMSE: 242.5892848450989, MAPE: 100.0\n",
      "Evaluating LSTM Model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/am/Documents/Software Development/10_Academy Training/week-11/portfolio-management-optimization/v-portfolio/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/home/am/Documents/Software Development/10_Academy Training/week-11/portfolio-management-optimization/v-portfolio/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 6s 21ms/step\n",
      "LSTM Model - MAE: 7.401479732629024, RMSE: 10.534666585638538, MAPE: 3.098880300155123\n",
      "\n",
      "Best performing model based on RMSE: ARIMA (Fixed)\n"
     ]
    }
   ],
   "source": [
    "# Compare models\n",
    "stock_forecasting.compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efe287c-a30d-47b1-85e9-395ff3670654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
